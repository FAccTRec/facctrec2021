---
title: Call for Papers
layout: page
permlink: /cfp/
---

<div style="color: red; margin-bottom: 5ex;">
DEADLINE EXTENSION: the deadline of the FAccTRec workshop is extended.  The authors have to register the abstract before <span style="font-weight: bold;">July 31</span>, and submit the paper <span style="font-weight: bold;">August 4</span>.
</div>

The 3rd FAccTRec Workshop on Responsible Recommendation
=====================================================

The 3rd FAccTRec Workshop on Responsible Recommendation at [RecSys 2020](https://recsys.acm.org/recsys20/) is a venue for discussing problems of social responsibility in maintaining, evaluating, and studying recommender systems. The importance of the problem is now increasing due to the empowerment of social networking technologies and the change of social environment, such as the enforcement of the EU General Data Protection Regulation. In this workshop, we welcome research and position papers about ethical, social, and legal issues brought by the development and the use of recommendation. And, we will conduct a discussion for research to contribute socially responsible recommendations.

Topics of Interest
------------------

FAccTRec stands for Fairness, Accountability and Transparency in Recommender Systems and aims to draw attention to these issues at ACM RecSys, as has been done in the machine learning community through events such as [FAccT conference](https://facctconference.org/). There are many potential aspects of responsibility in recommendation, including (but not limited to):

* Responsibility: what does it mean for a recommender system to be socially responsible? How can we assess the social and human impact of recommender systems?
* Fairness: what might ‘fairness’ mean in the context of recommendation? How could a recommender be unfair, and how could we measure such unfairness?
* Accountability: to whom, and under what standard, should a recommender system be accountable? How can or should it and its operators be held accountable? What harms should such accountability be designed to prevent?
* Transparency: what is the value of transparency in recommendation, and how might it be achieved? How might it trade off with other important concerns?
* Compliance: how should algorithms and especially recommendation algorithms be designed to adhere the laws or regulations, such as the [EU GDPR](http://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32016R0679) or the [IEEE EAD](https://ethicsinaction.ieee.org/)? How should data collection be rethought to meet those new privacy standards ? How to meet the requirements in terms of transparency and explainability of algorithmic decisions.
* Safety: how can a recommender system distort users' opinions? what is required to be resilient to such a distortion? What is a proper treatment of private or sensitive information when making recommendations?

Submission Guidelines 
---------------------

We encourage submissions in the above topics. No official proceedings will not be published, because the focus of this workshop is discussion about the directions to build and manage responsible recommender systems and to provide feedback on early-stage research. All accepted papers manuscripts will be expected to be posted on arXiv.org by the authors, and an arXiv Index will index the accepted papers. We allow manuscripts that have already published or that are currently submitted to another venue, so long as arXiv publication is compatible with that venue's requirements; already-published manuscripts should be accompanied by a cover abstract justifying their contribution specifically to FAccTRec.

Manuscripts must be submitted through an online submission system and will be reviewed by a program committee. The review process is a single-blind, the authors names do not need to be anonymized. Presentations will be held in an oral or a poster style.

### Position Papers

Position papers address one or more of the above themes, or practical issues in building responsible recommendations. These could be both research systems or production systems in industry. The number of pages should be limited to three (3) pages in the ACM manuscript format and two (2) pages in the ACM sigconf format.  You can omit the abstract in the article.

### Research Papers

Research papers present empirical or analytical results related to the social impact of recommender systems or algorithms. These could be explorations of bias in recommender systems (either live systems or sandboxed algorithms), explainability and transparency of recommender systems, experiments regarding the impact of the recommender on its users or others, etc. We will construe the topics broadly. The number of pages should be limited from five (5) to eight (8) pages in the ACM manuscript format and from four (4) to six (6) pages in the ACM sigconf format.

### Paper format

We encourage you to format in the [ACM manuscript / sigconf format](https://www.acm.org/publications/proceedings-template) with the subsequent options.

* \setcopyright{none}
* a `CCS` class and keywords parts can be omitted.

However, we will not limit to this format, and will accept one of the ACM sigconf,  the IEEE proceedings format, the NeurIPS format, and the ICML proceedings format.
The number of words should be limited to 2000 words for position papers, and 3000 - 5000 words for research papers.  Each display-style-equation is counted as 30 words and each figure or table is counted as 200 words.

### Submission

Papers should be submitted from the [EasyChair](https://easychair.org/conferences/?conf=facctrec2020).  Please do not forget to choose your type of submission: Position or Research.

Important Dates
---------------

* <del style="color: gray;">2020-07-29</del> 2020-07-31: Abstract registration deadline
* <del style="color: gray;">2020-07-29</del> 2020-08-04: Paper submission deadline
* <del style="color: gray;">2020-08-06</del> 2020-08-21: Author notification
* <del style="color: gray;">2020-09-03</del> 2020-09-04: Final version upload
* 2020-09-26: Workshop (full day)

TIMEZONE: Anywhere On Earth
